{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack exchange\n",
    "Pros\n",
    "the problems are highly realistic/human like\n",
    "have multiple references + a builtin rating/quality system because of upvotes\n",
    "tagged with useful information\n",
    " \n",
    "Cons\n",
    "it’s easy to lookup\n",
    "rate limits 10k per day\n",
    " \n",
    "Hugging face\n",
    "Pros\n",
    "massive\n",
    "multilingual\n",
    "real code\n",
    "\n",
    "Cons\n",
    "quality depends on our corruption procedure\n",
    "maybe lookup\n",
    "some garbage in the dataset\n",
    "kinda contrived (it’s more like a fill in the blanks dataset rather than true generation or debugging)\n",
    " \n",
    "DIY\n",
    "Pros\n",
    "way more control over the type of problem (eg python, data analysis, pandas)\n",
    "\n",
    "Cons\n",
    "probably only good at python and maybe JavaScript\n",
    "slow\n",
    "maybe wrong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing DIY creation of debug challenges based on LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/prompting/.venv/lib/python3.10/site-packages/eth_utils/network.py:44: UserWarning: Network 345 with name 'Yooldo Verse Mainnet' does not have a valid ChainId. eth-typing should be updated with the latest networks.\n",
      "  warnings.warn(\n",
      "/workspace/prompting/.venv/lib/python3.10/site-packages/eth_utils/network.py:44: UserWarning: Network 12611 with name 'Astar zkEVM' does not have a valid ChainId. eth-typing should be updated with the latest networks.\n",
      "  warnings.warn(\n",
      "/workspace/prompting/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-23 01:53:15,024\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-23 01:53:15,099\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "INFO:bittensor: - Available free memory: 84.53 GB - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-23 01:53:15.775 |       INFO      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bittensor: - Total gpu memory 84.97 GB - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |  - Available free memory: 84.53 GB - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bittensor: - 93.0% of the GPU memory will be utilized for loading the model to device \"cuda\". - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-23 01:53:15.781 |       INFO      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/prompting/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |  - Total gpu memory 84.97 GB - \n",
      "2024-05-23 01:53:15.785 |       INFO       |  - 93.0% of the GPU memory will be utilized for loading the model to device \"cuda\". - \n",
      "WARNING 05-23 01:53:15 config.py:173] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-23 01:53:15 llm_engine.py:73] Initializing an LLM engine with config: model='casperhansen/llama-3-70b-instruct-awq', tokenizer='casperhansen/llama-3-70b-instruct-awq', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=awq, seed=0)\n",
      "INFO 05-23 01:53:15 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 01:53:45 llm_engine.py:222] # GPU blocks: 5216, # CPU blocks: 819\n"
     ]
    }
   ],
   "source": [
    "from prompting.llms import vLLMPipeline\n",
    "model_id = \"casperhansen/llama-3-70b-instruct-awq\"\n",
    "device = 'cuda'\n",
    "gpus = 1\n",
    "max_allowed_memory_in_gb = 79\n",
    "pipeline = vLLMPipeline(device=device, model_id=model_id, gpus=gpus, llm_max_allowed_memory_in_gb=max_allowed_memory_in_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vLLM_LLM instance to try and create challenges for coding\n",
    "from prompting.llms import vLLM_LLM\n",
    "SYSTEM_PROMPT = \"You are a coding teacher. You make examples of code with bugs that students can solve. You do not announce what the bugs are.\"\n",
    "vllm = vLLM_LLM(llm_pipeline=pipeline, system_prompt=SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "INFO:bittensor: - vLLM_LLM generated the following output:\n",
      "\n",
      "\n",
      "Here is the modified code with a bug:\n",
      "\n",
      "```\n",
      "def add_numbers(a, b):\n",
      "    result = a - b\n",
      "    print(\"The sum is:\", result)\n",
      "    return result\n",
      "```\n",
      "\n",
      "Your turn to find and fix the bug! - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-23 01:53:49.741 |       INFO       |  - vLLM_LLM generated the following output:\n",
      "\n",
      "\n",
      "Here is the modified code with a bug:\n",
      "\n",
      "```\n",
      "def add_numbers(a, b):\n",
      "    result = a - b\n",
      "    print(\"The sum is:\", result)\n",
      "    return result\n",
      "```\n",
      "\n",
      "Your turn to find and fix the bug! - \n",
      "2024-05-23 01:53:54.774 |       INFO       |  - vLLM_LLM generated the following output:\n",
      "\n",
      "\n",
      "{{ \n",
      "\n",
      "The bug in this code is that it is subtracting `b` from `a` instead of adding them together. Here is the corrected code:\n",
      "\n",
      "```\n",
      "def add_numbers(a, b):\n",
      "    result = a + b\n",
      "    print(\"The sum is:\", result)\n",
      "    return result\n",
      "```\n",
      "\n",
      "Now, the function correctly adds `a` and `b` together and returns the result. }} - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nHere is the modified code with a bug:\\n\\n```\\ndef add_numbers(a, b):\\n    result = a - b\\n    print(\"The sum is:\", result)\\n    return result\\n```\\n\\nYour turn to find and fix the bug!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm.query(message=\"\"\"\n",
    "           Add a bug to the following code:\n",
    "           ```\n",
    "    def add_numbers(a, b):\n",
    "        result = a + b\n",
    "        print(\"The sum is:\", result)\n",
    "        return result\n",
    "    ```\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.01s/it]\n",
      "INFO:bittensor: - vLLM_LLM generated the following output:\n",
      "\n",
      "\n",
      "{{ \n",
      "\n",
      "The bug in this code is that it is subtracting `b` from `a` instead of adding them together. Here is the corrected code:\n",
      "\n",
      "```\n",
      "def add_numbers(a, b):\n",
      "    result = a + b\n",
      "    print(\"The sum is:\", result)\n",
      "    return result\n",
      "```\n",
      "\n",
      "Now, the function correctly adds `a` and `b` together and returns the result. }} - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n{{ \\n\\nThe bug in this code is that it is subtracting `b` from `a` instead of adding them together. Here is the corrected code:\\n\\n```\\ndef add_numbers(a, b):\\n    result = a + b\\n    print(\"The sum is:\", result)\\n    return result\\n```\\n\\nNow, the function correctly adds `a` and `b` together and returns the result. }}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm.query(message=\"\"\"fix this code def add_numbers(a, b):\n",
    "    result = a - b\n",
    "    print(\"The sum is:\", result)\n",
    "    return result\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully Created a code based on verbal queues \"vllm.query(message=\"Create a funciton that calculates the sum of two numbers, but introduce a bug\")\n",
    "# vllm.query(message=\"\"\"\n",
    "    #       Add a bug to the following code:\n",
    "    #        ```\n",
    "    # def add_numbers(a, b):\n",
    "    #     result = a + b\n",
    "    #     print(\"The sum is:\", result)\n",
    "    #     return result\n",
    "    # ```\"\"\") was also a success, do this more rigorously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/*\\n * Copyright (c) 1999, Oracle and/or its affiliates. All rights reserved.\\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\\n *\\n * This code is free software; you can redistribute it and/or modify it\\n * under the terms of the GNU General Public License version 2 only, as\\n * published by the Free Software Foundation.  Oracle designates this\\n * particular file as subject to the \"Classpath\" exception as provided\\n * by Oracle in the LICENSE file that accompanied this code.\\n *\\n * This code is distributed in the hope that it will be useful, but WITHOUT\\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\\n * version 2 for more details (a copy is included in the LICENSE file that\\n * accompanied this code).\\n *\\n * You should have received a copy of the GNU General Public License version\\n * 2 along with this work; if not, write to the Free Software Foundation,\\n * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\\n *\\n * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\\n * or visit www.oracle.com if you need additional information or have any\\n * questions.\\n */\\n\\npackage krb.javax.naming;\\n\\n/**\\n  * This interface is implemented by an object that can provide a\\n  * Reference to itself.\\n  *<p>\\n  * A Reference represents a way of recording address information about\\n  * objects which themselves are not directly bound to the naming system.\\n  * Such objects can implement the Referenceable interface as a way\\n  * for programs that use that object to determine what its Reference is.\\n  * For example, when binding a object, if an object implements the\\n  * Referenceable interface, getReference() can be invoked on the object to\\n  * get its Reference to use for binding.\\n  *\\n  * @author Rosanna Lee\\n  * @author Scott Seligman\\n  * @author R. Vasudevan\\n  *\\n  * @see Context#bind\\n  * @see krb.javax.naming.spi.NamingManager#getObjectInstance\\n  * @see Reference\\n  * @since 1.3\\n  */\\npublic interface Referenceable {\\n    /**\\n      * Retrieves the Reference of this object.\\n      *\\n      * @return The non-null Reference of this object.\\n      * @exception NamingException If a naming exception was encountered\\n      *         while retrieving the reference.\\n      */\\n    Reference getReference() throws NamingException;\\n}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompting.tools.datasets.code import  HFCodingDataset\n",
    "data = HFCodingDataset(seed=42)\n",
    "data.random()['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<prompting.tools.datasets.code.HFCodingDataset at 0x7f0120372290>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/prompting/.venv/lib/python3.10/site-packages/eth_utils/network.py:44: UserWarning: Network 345 with name 'Yooldo Verse Mainnet' does not have a valid ChainId. eth-typing should be updated with the latest networks.\n",
      "  warnings.warn(\n",
      "/workspace/prompting/.venv/lib/python3.10/site-packages/eth_utils/network.py:44: UserWarning: Network 12611 with name 'Astar zkEVM' does not have a valid ChainId. eth-typing should be updated with the latest networks.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bittensor as bt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = bt.metagraph(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2543521)\n",
      "tensor(2541467)\n",
      "tensor(3013814)\n",
      "tensor(3199766)\n",
      "tensor(2537782)\n",
      "tensor(3199739)\n",
      "tensor(3199759)\n",
      "tensor(2543778)\n",
      "tensor(2541453)\n",
      "tensor(2543703)\n",
      "tensor(2541610)\n",
      "tensor(2542185)\n",
      "tensor(3199790)\n",
      "tensor(2523560)\n",
      "tensor(2543260)\n",
      "tensor(2543744)\n",
      "tensor(2542167)\n",
      "tensor(2542432)\n",
      "tensor(2543193)\n",
      "tensor(2542761)\n",
      "tensor(2543674)\n",
      "tensor(2543743)\n",
      "tensor(2542021)\n",
      "tensor(2543612)\n",
      "tensor(2533379)\n",
      "tensor(2541329)\n",
      "tensor(2539029)\n",
      "tensor(2543417)\n",
      "tensor(2543779)\n",
      "tensor(2536059)\n",
      "tensor(2543191)\n",
      "tensor(2524007)\n",
      "tensor(2537521)\n",
      "tensor(2543795)\n",
      "tensor(2543252)\n",
      "tensor(2461514)\n",
      "tensor(2541324)\n",
      "tensor(2541205)\n",
      "tensor(2537747)\n",
      "tensor(2542078)\n",
      "tensor(2543728)\n",
      "tensor(2543480)\n",
      "tensor(2543656)\n",
      "tensor(2542418)\n",
      "tensor(2402890)\n",
      "tensor(2540964)\n",
      "tensor(2543174)\n",
      "tensor(2543045)\n",
      "tensor(2543108)\n",
      "tensor(2542834)\n",
      "tensor(2865084)\n",
      "tensor(2542698)\n",
      "tensor(2542791)\n",
      "tensor(2497745)\n",
      "tensor(2543373)\n",
      "tensor(2542367)\n",
      "tensor(2543360)\n",
      "tensor(2539824)\n",
      "tensor(2543091)\n",
      "tensor(2543693)\n",
      "tensor(2441671)\n",
      "tensor(3161394)\n",
      "tensor(2543535)\n",
      "tensor(2536470)\n",
      "tensor(3199748)\n",
      "tensor(2543764)\n",
      "tensor(2542610)\n",
      "tensor(2540445)\n",
      "tensor(2540489)\n",
      "tensor(2538220)\n",
      "tensor(2541305)\n",
      "tensor(2541792)\n",
      "tensor(2461473)\n",
      "tensor(2541649)\n",
      "tensor(2543314)\n",
      "tensor(2674269)\n",
      "tensor(2542242)\n",
      "tensor(2542832)\n",
      "tensor(2539401)\n",
      "tensor(2542552)\n",
      "tensor(2500026)\n",
      "tensor(2534262)\n",
      "tensor(2542072)\n",
      "tensor(2541773)\n",
      "tensor(2536371)\n",
      "tensor(2543710)\n",
      "tensor(2536690)\n",
      "tensor(2542756)\n",
      "tensor(2541846)\n",
      "tensor(2541081)\n",
      "tensor(2542833)\n",
      "tensor(2543795)\n",
      "tensor(2542836)\n",
      "tensor(2537101)\n",
      "tensor(2543439)\n",
      "tensor(2540843)\n",
      "tensor(2500506)\n",
      "tensor(2525060)\n",
      "tensor(2540576)\n",
      "tensor(2542571)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(meta.last_update[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(3199800)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2541234, 2538032, 2541840, 2540085, 2542065, 2542650, 2542774,\n",
       "       2534172, 2543119, 2543119, 2542781, 2542735, 2542011, 2543237,\n",
       "       2540374, 2543187, 2540974, 2538529, 2541740, 2538503, 2543208,\n",
       "       2540600, 2540313, 2543073, 2543280, 2540852, 2539040, 2542569,\n",
       "       2543022, 2541128, 2542105, 2542877, 2542851, 2541277, 2539707,\n",
       "       2402995, 2541594, 2511388, 2541450, 2543170, 2543183, 2539434,\n",
       "       2542615, 2542893, 2543260, 2542734, 2542089, 2542916, 2527229,\n",
       "       2538399, 2541479, 2541212, 2541587, 2540581, 2540522, 2536836,\n",
       "       2542982, 2540044, 2541273, 2540350, 2541614, 2542531, 2543094,\n",
       "       2543319, 2540189, 2542643, 2542135, 2543189, 2461523, 2538593,\n",
       "       2541257, 2542263, 2539004, 2540121, 2538357, 2537444, 2542356,\n",
       "       2543392, 2543129, 2402942, 2541090, 2541468, 2542525, 2542116,\n",
       "       2543202, 2530817, 2542665, 2542507, 2511040, 2542438, 2543106,\n",
       "       2528938, 2542962, 2540093, 2543327, 2542093, 2542765, 2543261,\n",
       "       2542764, 2542028, 2461539, 2522346, 2422203, 2543021, 2539873,\n",
       "       2543173, 2540957, 2543310, 2542925, 2538963, 2542612, 2543108,\n",
       "       2543164, 2402928, 2538194, 2542350, 2528144, 2540961, 2543144,\n",
       "       2540607, 2402952, 2542971, 2541996, 2542088, 2542031, 2542697,\n",
       "       2540740, 2540618, 2541517, 2542756, 2543242, 2538501, 2541525,\n",
       "       2539765, 2521376, 2542540, 2542699, 2543311, 2542147, 2542265,\n",
       "       2540116, 2543381, 2487813, 2539014, 2528159, 2543034, 2535916,\n",
       "       2541254, 2543089, 2539534, 2542930, 2542562, 2543004, 2541018,\n",
       "       2540078, 2524225, 2543084, 2543368, 2543270, 2540806, 2540006,\n",
       "       2541359, 2540117, 2542080, 2541722, 2542670, 2541738, 2540328,\n",
       "       2531074, 2542239, 2503575, 2539710, 2540413, 2541346, 2540826,\n",
       "       2518440, 2542073, 2541721, 2541470, 2422185, 2541069, 2541474,\n",
       "       2543341, 2540566, 2422171, 2525336, 2402988, 2543026, 2542865,\n",
       "       2538239, 2542066, 2540782, 2506175, 2402935, 2528476, 2422219,\n",
       "       2538858, 2540895, 2519986, 2537143, 2541116, 2541491, 2542622,\n",
       "       2530918, 2542359, 2542137, 2542958, 2533369, 2503659, 2540576,\n",
       "       2542505, 2542458, 2542695, 2543012, 2540535, 2542015, 2541508,\n",
       "       2540899, 2494626, 2541463, 2529902, 2528126, 2540186, 2543222,\n",
       "       2527873, 2542100, 2542478, 2542526, 2542602, 2541650, 2541485,\n",
       "       2521061, 2542495, 2542767, 2543194, 2542718, 2539508, 2541566,\n",
       "       2540287, 2542625, 2543236, 2541842, 2541554, 2528400, 2542009,\n",
       "       2541592, 2513299, 2525855, 2541862, 2541481, 2543249, 2542848,\n",
       "       2402885, 2542698, 2530550, 2543386, 2469025, 2542699, 2542286,\n",
       "       2500540, 2533928, 2540658, 2520748, 2541444, 2540631, 2540147,\n",
       "       2530872, 2526207, 2539986, 2540814, 2461506, 2540585, 2461501,\n",
       "       2542152, 2541720, 2529016, 2537471, 2542785, 2542104, 2540784,\n",
       "       2528105, 2542768, 2541477, 2541620, 2543083, 2540915, 2539757,\n",
       "       2540570, 2542592, 2543138, 2542868, 2511588, 2543376, 2543362,\n",
       "       2542553, 2542453, 2523408, 2528049, 2542241, 2542934, 2542540,\n",
       "       2541580, 2543330, 2422238, 2540878, 2540445, 2536807, 2538163,\n",
       "       2529552, 2543258, 2540920, 2540384, 2539816, 2542984, 2506059,\n",
       "       2541765, 2538762, 2542621, 2543018, 2537355, 2540817, 2540612,\n",
       "       2521232, 2542587, 2540373, 2541286, 2543303, 2542584, 2521354,\n",
       "       2542933, 2543064, 2543012, 2542767, 2541802, 2538754, 2543187,\n",
       "       2542236, 2537351, 2543188, 2540577, 2542896, 2542624, 2540097,\n",
       "       2542674, 2543346, 2520824, 2537876, 2541646, 2542309, 2538469,\n",
       "       2543293, 2542861, 2539789, 2541336, 2538736, 2461474, 2542206,\n",
       "       2542971, 2537848, 2540581, 2542102, 2536444, 2542466, 2542805,\n",
       "       2539853, 2542011, 2536819, 2523525, 2542931, 2543114, 2541534,\n",
       "       2521965, 2542303, 2543067, 2541357, 2541199, 2487844, 2542068,\n",
       "       2506644, 2540319, 2539215, 2541743, 2543214, 2531362, 2540348,\n",
       "       2543028, 2511224, 2541467, 2522079, 2542669, 2543042, 2527043,\n",
       "       2541131, 2542153, 2543064, 2541230, 2542391, 2542006, 2538382,\n",
       "       2543179, 2543095, 2542892, 2542984, 2543047, 2540804, 2542744,\n",
       "       2541045, 2538813, 2542958, 2543401, 2540473, 2539137, 2543350,\n",
       "       2541654, 2542742, 2542953, 2543315, 2537474, 2527487, 2540737,\n",
       "       2542636, 2542032, 2541109, 2542572, 2542689, 2542706, 2543084,\n",
       "       2542687, 2543337, 2542737, 2539678, 2530820, 2542944, 2540708,\n",
       "       2543213, 2541979, 2542267, 2540369, 2542184, 2524662, 2543071,\n",
       "       2542796, 2537829, 2542689, 2402996, 2542895, 2541208, 2541314,\n",
       "       2525639, 2539012, 2542847, 2542354, 2541452, 2402983, 2542517,\n",
       "       2540848, 2540413, 2541854, 2541689, 2543064, 2542564, 2528684,\n",
       "       2543373, 2541570, 2543355, 2524070, 2541757, 2492863, 2522015,\n",
       "       2543115, 2495780, 2543255, 2542764, 2541747, 2542955, 2510635,\n",
       "       2541201, 2461503, 2541636, 2542366, 2541281, 2541648, 2543185,\n",
       "       2537339, 2523755, 2540975, 2543281, 2543026, 2542454, 2542841,\n",
       "       2542409, 2541435, 2543099, 2542207, 2406176, 2540891, 2543382,\n",
       "       2539142, 2541281, 2542531, 2540690, 2542792, 2542950, 2541932,\n",
       "       2543145, 2541869, 2542175, 2541442, 2541372, 2542713, 2542691,\n",
       "       2422191, 2523845, 2542231, 2541522, 2520211, 2542082, 2541090,\n",
       "       2542344, 2542464, 2542889, 2534436, 2542132, 2541536, 2543148,\n",
       "       2543034, 2541669, 2543371, 2542747, 2510405, 2543088, 2542655,\n",
       "       2542596, 2542228, 2539784, 2543153, 2539042, 2541935, 2521035,\n",
       "       2543364, 2402934, 2542586, 2540443, 2537305, 2542257, 2542905,\n",
       "       2536622, 2542742, 2541455, 2542360, 2461515, 2543070, 2541511,\n",
       "       2502179, 2541749, 2542842, 2541656, 2536978, 2542996, 2537941,\n",
       "       2542603, 2526961, 2540531, 2539535, 2541473, 2543203, 2539548,\n",
       "       2540927, 2543081, 2542160, 2536096, 2542250, 2521653, 2543211,\n",
       "       2542920, 2422261, 2541389, 2540650, 2540184, 2542659, 2528098,\n",
       "       2540193, 2540751, 2535272, 2537970, 2540256, 2542028, 2543088,\n",
       "       2542962, 2539359, 2539358, 2541526, 2510190, 2543194, 2538257,\n",
       "       2539010, 2542145, 2543030, 2540736, 2543230, 2542721, 2535902,\n",
       "       2538933, 2542691, 2534863, 2521476, 2535863, 2541893, 2542564,\n",
       "       2526093, 2541533, 2540714, 2508752, 2542587, 2541345, 2543305,\n",
       "       2537746, 2541486, 2542802, 2540683, 2543360, 2500502, 2540118,\n",
       "       2542612, 2461582, 2542539, 2540176, 2543021, 2531732, 2536659,\n",
       "       2542236, 2422237, 2542516, 2506928, 2543028, 2542027, 2542185,\n",
       "       2543112, 2543117, 2542676, 2542986, 2540867, 2543033, 2543353,\n",
       "       2542904, 2541301, 2540719, 2515965, 2461474, 2542411, 2542997,\n",
       "       2542498, 2542016, 2543404, 2528165, 2540621, 2542383, 2541320,\n",
       "       2543329, 2540459, 2538701, 2541735, 2541690, 2521348, 2540357,\n",
       "       2539237, 2541819, 2538683, 2542570, 2536452, 2543036, 2541574,\n",
       "       2541562, 2540273, 2543347, 2541415, 2542966, 2543340, 2542035,\n",
       "       2540256, 2543401, 2542860, 2541947, 2543405, 2543645, 2543521,\n",
       "       2543550, 2543703, 2543710, 2543491, 2543537, 2543741, 2543740,\n",
       "       2543744, 2543674, 2543565, 2543628, 2543550, 2543637, 2543549,\n",
       "       2543743, 2543693, 2543679, 2543750, 2543706, 2543741, 2543517,\n",
       "       2543612, 2543716, 2543417, 2543513, 2543773, 2543721, 2543680,\n",
       "       2543728, 2543677, 2543772, 2543603, 2543500, 2543480, 2543454,\n",
       "       2543656, 2543694, 2543750, 2543751, 2543678, 2543686, 2543554,\n",
       "       2543659, 2543742, 2543693, 2543562, 2543697, 2543535, 2543568,\n",
       "       2543416, 2543553, 2543661, 2543728, 2543535, 2543577, 2543608,\n",
       "       2543685, 2543657, 2543755, 2543764, 2543710, 2543439, 2543773,\n",
       "       2543761, 2543563, 2543658, 2543562, 2543678, 2543724, 2543765,\n",
       "       2543764, 2543693, 2543713, 2543771, 2543693, 2543600, 2543706,\n",
       "       2543441, 2543767, 2543582, 2543553, 2543715, 2543589, 2543450,\n",
       "       2543652, 2543709, 2543561, 2543752, 2543424, 2543704, 2543713,\n",
       "       2543414, 2543771, 2543705, 2543573, 2543739, 2543560, 2543511,\n",
       "       2543682, 2543550, 2543420, 2543493, 2543480, 2543745, 2543654,\n",
       "       2543765, 2543766, 2543709, 2543652, 2543489, 2543409, 2543697,\n",
       "       2543449, 2543729, 2543773, 2543533, 2543723, 2543584, 2543563,\n",
       "       2543735, 2543417, 2543481, 2543514, 2543647, 2543755, 2543568,\n",
       "       2543477, 2543714, 2543478, 2543562, 2543739, 2543643, 2543590,\n",
       "       2543624, 2543641, 2543460, 2543628, 2543457, 2543692, 2543623,\n",
       "       2543670, 2543757, 2543710, 2543761, 2543752, 2543630, 2543758,\n",
       "       2543775, 2543795, 2543785, 2543782, 2543778, 2543795, 2543794,\n",
       "       2655007, 2569863, 2543781, 2543781, 2543791, 2543779, 2585404,\n",
       "       2543783, 2543795, 2543777, 2543776, 2543785, 2543782, 2543786,\n",
       "       2632461, 2543782, 2642690, 2543785, 2655841, 2674269, 2705898,\n",
       "       2748451, 2737684, 2706059, 2808304, 2690538, 2730215, 2834076,\n",
       "       2878184, 3199698, 3161266, 3199712, 3199709, 3161393, 3161394,\n",
       "       3199707, 3013814, 2986074, 2865084, 3161371, 3199691, 3199639,\n",
       "       3199699, 3158767, 3198960, 3086371, 3199714, 3199715, 3199736,\n",
       "       3199739, 3199743, 3199759, 3199748, 3199759, 3199790, 3199787,\n",
       "       3199766, 3199771, 3199772, 3199774])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through the values of meta.last_update, and get the 10 max values\n",
    "import numpy as np\n",
    "max_values = np.partition(meta.last_update, -10)[-900:]\n",
    "max_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
